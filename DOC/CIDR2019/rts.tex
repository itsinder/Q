\section{Q's Run Time System}

Q is a high-performance ``almost-relational'' 
analytical, single-node, column-store database. 
\be
\item 
By ``analytical'' we mean that data changes at the user's behest (e.g.
loading a data set) but is not subject to external events.
\item 
By ``almost-relational'' we mean that it would more correctly
be called a ``tabular model'' \cite{Codd1982}. As Codd states, ``Tables are
at a lower level of abstraction than relations, since they give
the impression that positional (array-type) addressing is applicable
(which is not true of \(n\)-ary relations), and they fail to
show that the information content of a table is independent
of row order. Nevertheless, even with these minor flaws,
tables are the most important conceptual representation of
relations, because they are universally understood.''
\item By ``single-node'', we mean that Q does not distribute computation across
  machines. The flow of execution is inherently single-threaded. However,
  pthreads and OpenMP are heavily used {\em within} individual operations so as
  to exploit multi-core systems as well as GPUs.
\item By ``column-store'', we mean that 
Q provides the Lua programmer with the Vector type, each
individual element of which is a Scalar. A table in Q is a Lua
table of Vectors (Section~\ref{vectors_versus_tables}), where a Lua table is an
associative array, like a Python dictionary.

\ee

\subsection{Q as a Lua extension}


It is useful to think of Q as a domain specific language, targeted for data
manipulation. In this sense alone, it is similar to the 
effort to develop a persistent functional language,
and implement a relational database system inside
this language  \cite{Wevers2014}.
More accurately, Q is a C library, embedded within an interpreted
language.
We chose to embed within an existing language for two reasons. One is that we did not have to
write a custom compiler. More importantly, is that it allowed us to leverage a rich eco-system of libraries, debuggers
\ldots
yet seamlessly move between that world and the high performance capabilities of
Q. 

We chose Lua
because it was designed specifically as both an embedding and embedded language
\cite{Lua2011} and it had a wickedly fast interpreter, LuaJIT.
We experimented with several approaches to invoking C from Lua. These included
(a) dyncall \cite{Adler2013} (b) the native Lua C API (c) LuaFFI (d) LuaJIT's
FFI. Taking the native Lua C API as the baseline, dyncall was (surprisingly) the worst (twice
as slow) and LuaJIT was (unsurprisingly) the fastest (50 times as fast!).

Data is stored in memory and, when necessary, persisted (uncompressed) in
binary format to the file system. This allows us to quickly access data by
mmapp-ing the file.  Like kdb+ \cite{Borror2015}, one can think of Q as 
an in-memory database with persistent backing to the file system.

How efficient is the combination of Lua and C? On representative code samples,
XX\% of the time is spent in the C code that does the real work, YY\% of the
time is spent in the core run time system, with the Lua glue code accounting for
the rest. 
%% TODO FILL IN THE XX and YY

Q's software architecture consists of the following four layers. As we go from
bottom to top, the rate of change increases and the complexity decreases.
\be
\item The core run time system --- Vectors, Scalars, Reducers
\item operators --- provides core functionality (using C, OpenMP, pthreads) on
  top of run time
\item Q library developers --- use Q and Lua to create higher level functions on
  top of core operators
\item Q programmers --- use Q much the way  Python programmer uses scikit-learn.
  \ee

\input{vectors}

\input{reducers}

\input{polymorphism}

% \input{glossary}
