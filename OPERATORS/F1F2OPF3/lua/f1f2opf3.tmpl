-- CUDA: template change for cuda programming
return require 'Q/UTILS/lua/code_gen' {

   declaration = [[
#include "q_incs.h"
${includes}
extern int
${fn}(
// Removed the 'restrict' keyworkd from below lines as nvcc compiler was recognising it
      const ${in1_ctype} * in1,  
      const ${in2_ctype} * in2,  
      uint64_t nR,  
      ${out_ctype} *  out 
      ) 
;

   ]],
   definition = [[
extern "C" {
#include "_${fn}.h"
}
__global__
static void
__operation(
      ${in1_ctype} *d_a,
      ${in2_ctype} *d_b, 
      ${out_ctype} *d_c,
      uint64_t size
      )
      {
      uint64_t index = blockIdx.x * blockDim.x + threadIdx.x;
      uint64_t stride = blockDim.x * gridDim.x;
      for (uint64_t i = index; i < size; i += stride) {
        ${c_code_for_operator}
      }
      }

int
${fn}(  
      const ${in1_ctype} * in1,  
      const ${in2_ctype} * in2,  
      uint64_t nR,  
      ${out_ctype} * out 
      )

{ 
  int status = 0;
// TODO #pragma omp parallel for schedule(static, Q_MIN_CHUNK_SIZE_OPENMP)

  // Declare pointers to device array
  ${in1_ctype} *d_in1 = 0;
  ${in2_ctype} *d_in2 = 0;
  ${out_ctype} *d_out = 0;

  // Allocate memory for device arrays
  cudaMalloc (&d_in1, nR * sizeof (${in1_ctype}));
  cudaMalloc (&d_in2, nR * sizeof (${in2_ctype}));
  cudaMalloc (&d_out, nR * sizeof (${out_ctype}));

  // Copy input from host to device
  cudaMemcpy (d_in1, in1, nR * sizeof(${in1_ctype}), cudaMemcpyHostToDevice);
  cudaMemcpy (d_in2, in2, nR * sizeof(${in2_ctype}), cudaMemcpyHostToDevice);

  // Decide runtime configuration
  uint64_t blockSize = 256;
  uint64_t numBlocks = (nR + 256 - 1) / blockSize;

  // Launch Kernel
  __operation<<<numBlocks, blockSize>>>(d_in1, d_in2, d_out, nR);

  // Copy result from device to host
  cudaMemcpy (out, d_out, nR * sizeof(${out_ctype}), cudaMemcpyDeviceToHost);
  
  return status;
}

   ]]
}
